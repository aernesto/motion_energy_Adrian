{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#NB-description\" data-toc-modified-id=\"NB-description-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>NB description</a></span></li><li><span><a href=\"#The-dotsPositions.csv-data\" data-toc-modified-id=\"The-dotsPositions.csv-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>The dotsPositions.csv data</a></span></li><li><span><a href=\"#Write-a-dotsDB-HDF5-file\" data-toc-modified-id=\"Write-a-dotsDB-HDF5-file-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Write a dotsDB HDF5 file</a></span><ul class=\"toc-item\"><li><span><a href=\"#Mapping-dots-to-trials\" data-toc-modified-id=\"Mapping-dots-to-trials-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Mapping dots to trials</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB description\n",
    "date: 11 Nov 2019  \n",
    "This notebook contains code that:\n",
    "- builds an HDF5 dotsDB database off of dotsPositions.csv files from the Pilot run (summer 2019)\n",
    "- reads off trials from the HDF5 db in order to compute motion energy\n",
    "- plots reverse kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import seaborn as sns\n",
    "import h5py     \n",
    "\n",
    "# add location of custom modules to path\n",
    "sys.path.insert(0,'../modules/')\n",
    "sys.path.insert(0,'../modules/dots_db/dotsDB/')\n",
    "\n",
    "# custom modules\n",
    "import dotsDB as ddb\n",
    "import motionenergy as kiani_me\n",
    "import stimulus as stim\n",
    "import ME_functions as my_me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dotsPositions.csv data\n",
    "The first step is to find what .csv files we have. What I do below is that I inspect a few .csv files and then concatenate them all into a single pandas DataFrame and dump it to file (I only retain active dots info)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !find /home/adrian/SingleCP_DotsReversal/raw -name \"*dotsPositions.csv\" -print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOTS_DATA = '/home/adrian/SingleCP_DotsReversal/processed/dots_pilot_summer_2019.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_csv(df):\n",
    "    \"\"\"df is a pandas.DataFrame\"\"\"\n",
    "    print(df.head())\n",
    "    print(len(df))\n",
    "    print(np.unique(df['taskID']))\n",
    "    try:\n",
    "        print(np.unique(df['pilotID']))\n",
    "    except KeyError:\n",
    "        print(np.unique(df['subject']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pd.read_csv('/home/adrian/SingleCP_DotsReversal/raw/2019_06_25_13_24/2019_06_25_13_24_dotsPositions.csv')\n",
    "# inspect_csv(a)\n",
    "\n",
    "# b = pd.read_csv('/home/adrian/SingleCP_DotsReversal/raw/2019_07_03_15_03/2019_07_03_15_03_dotsPositions.csv')\n",
    "# inspect_csv(b)\n",
    "\n",
    "# c = pd.read_csv('/home/adrian/SingleCP_DotsReversal/raw/2019_07_10_17_19/2019_07_10_17_19_dotsPositions.csv')\n",
    "# inspect_csv(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = [\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_06_25_13_24/2019_06_25_13_24_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_07_03_15_03/2019_07_03_15_03_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_06_24_13_31/2019_06_24_13_31_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_06_24_13_06/2019_06_24_13_06_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_07_17_17_17/2019_07_17_17_17_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_07_10_12_18/2019_07_10_12_18_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_06_20_13_27/2019_06_20_13_27_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_06_24_12_38/2019_06_24_12_38_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_07_10_17_19/2019_07_10_17_19_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_06_20_12_54/2019_06_20_12_54_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_06_21_13_08/2019_06_21_13_08_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_07_12_11_11/2019_07_12_11_11_dotsPositions.csv'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas = [pd.read_csv(f) for f in files]\n",
    "# total = pd.concat(pandas)\n",
    "# inspect_csv(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final = total.loc[total['isActive'] == 1,:]\n",
    "# inspect_csv(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_to_file = False\n",
    "# if write_to_file:\n",
    "#     final.to_csv('dots_pilot_summer_2019.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a dotsDB HDF5 file\n",
    "Now that all the dotsPositions.csv data is collected into a single global .csv file, I wish to dump it all into an hdf5 database.\n",
    "\n",
    "Several actions need to be implemented.\n",
    "1. For each trial in the dotsPositions.csv data, I need to know: _coherence_, _viewing duration_, _presenceCP_, _direction_, _subject_, _block_ (_probCP_). For this, I will assume that the `trialEnd` (from FIRA) and `seqDumpTime` (from dotsPositions) timestamps are in the same unit.\n",
    "2. I need to decide how to organize my dotsDB hierarchically. Example is `subj15/probCP0.1/coh0/ansleft/CPno/VD100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Needs to be re-written\n",
    "# def snowDots2DotsDBNormalizedFrames(df):\n",
    "#     \"\"\"\n",
    "#     Casts a pandas.DataFrame corresponding to the .csv file outputted by some snow-dots programs into a list of \n",
    "#     lists of frames, as dotsDB accepts them. The main mapping is the swapping of x and y.\n",
    "    \n",
    "#     In dotsDB, x represents vertical position, y horizontal, and (0,0) is top left corner.\n",
    "#     In snow-dots, x represents horizontal position, y vertical, and (0,0) is top left corner.\n",
    "      \n",
    "#     :param df: dataframe with columns \"xpos\", \"ypos\", \"isActive\", \"isCoherent\", \"frameIdx\", \n",
    "#          \"seqDumpTime\", \"pilotID\", \"taskID\", \"trialCount\" \n",
    "#     :type df: pandas.DataFrame\n",
    "#     \"\"\"\n",
    "#     list_of_trials = []\n",
    "# #     num_trials = np.max(df[\"trialCount\"])\n",
    "#     for tr in range(num_trials):\n",
    "#         list_of_frames = []\n",
    "# #         trial_data = df[df[\"trialCount\"] == (tr+1)]\n",
    "        \n",
    "#         num_frames = np.max(trial_data[\"frameIdx\"])\n",
    "#         assert not np.isnan(num_frames), f'trial {tr+1}, num_frames is {num_frames}'\n",
    "        \n",
    "#         for fr in range(num_frames):\n",
    "#             frame_data = trial_data[(trial_data[\"frameIdx\"] == (fr+1)) & (trial_data[\"isActive\"] == 1)]\n",
    "#             list_of_frames.append(np.array(frame_data[['ypos','xpos']]))  # here I swap xpos with ypos\n",
    "        \n",
    "#         list_of_trials.append(list_of_frames)\n",
    "#     return list_of_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('/home/adrian/SingleCP_DotsReversal/processed/all_valid_data.csv')\n",
    "d = pd.read_csv(DOTS_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       xpos      ypos  isActive  isCoherent  frameIdx   seqDumpTime  pilotID  \\\n",
      "0  0.996977  0.013053         1           1         1  1.204152e+06        2   \n",
      "1  0.828417  0.618607         1           1         1  1.204152e+06        2   \n",
      "2  0.378624  0.591975         1           1         1  1.204152e+06        2   \n",
      "3  0.748699  0.621605         1           1         1  1.204152e+06        2   \n",
      "4  0.675888  0.318813         1           1         1  1.204152e+06        2   \n",
      "\n",
      "   taskID  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n",
      "1906784\n",
      "[ 1  2  3  4  5  6  7  8 10 11 12 13 14]\n",
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "inspect_csv(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subject              date  taskID  trialIndex     trialStart       trialEnd  \\\n",
      "0      S1  2019_06_20_12_54       2           1  769481.078453  769485.302769   \n",
      "1      S1  2019_06_20_12_54       2           2  769491.408107  769495.878215   \n",
      "2      S1  2019_06_20_12_54       2           3  769495.881308  769501.918366   \n",
      "3      S1  2019_06_20_12_54       2           4  769501.921422  769505.751018   \n",
      "4      S1  2019_06_20_12_54       2           5  769505.754041  769510.374374   \n",
      "\n",
      "      dirRT  dirChoice  dirCorrect  cpRT  ...  targetOn    dotsOn   dotsOff  \\\n",
      "0  0.584855        1.0         1.0   NaN  ...  1.532990  2.092313  2.516041   \n",
      "1  0.433302        0.0         1.0   NaN  ...  0.745712  2.491474  2.913933   \n",
      "2  0.583730        1.0         1.0   NaN  ...  1.169542  3.931527  4.338307   \n",
      "3  0.480400        0.0         1.0   NaN  ...  1.179547  1.806666  2.225525   \n",
      "4  1.230994        1.0         1.0   NaN  ...  1.206468  1.850535  2.274264   \n",
      "\n",
      "   dirChoiceTime  cpChoiceTime  CPresponseSide  startResponseTwo  block  day  \\\n",
      "0       3.100896           NaN             1.0               NaN  Quest    1   \n",
      "1       3.347234           NaN             1.0               NaN  Quest    1   \n",
      "2       4.922037           NaN             1.0               NaN  Quest    1   \n",
      "3       2.705924           NaN             0.0               NaN  Quest    1   \n",
      "4       3.505259           NaN             1.0               NaN  Quest    1   \n",
      "\n",
      "   probCP  \n",
      "0     NaN  \n",
      "1     NaN  \n",
      "2     NaN  \n",
      "3     NaN  \n",
      "4     NaN  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "11351\n",
      "[ 2  4  6  7  8  9 10 11 12 13 14]\n",
      "['S1' 'S2' 'S3' 'S4' 'S5']\n"
     ]
    }
   ],
   "source": [
    "inspect_csv(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.unique(d['seqDumpTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5976"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5976,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots_dump_time = np.min(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1205490.81387667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = np.unique(t['trialEnd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11351,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386.872299287"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1209099.79360426"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping dots to trials\n",
    "Having the dump times of the dots and of the trials, our first task is to recover from which trial each dot is from.\n",
    "\n",
    "Let's start simple, with the first dump times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_params(df):\n",
    "    \"\"\"coherence, viewing duration, presenceCP, direction, subject, block (probCP)\"\"\"\n",
    "    print(\n",
    "        'coh {}, VD {}, CP {}, dir {}, {}, {}, probCP {}'.format(\n",
    "            df['coherence'].values[0],\n",
    "            df['viewingDuration'].values[0],\n",
    "            df['presenceCP'].values[0],\n",
    "            df['initDirection'].values[0],\n",
    "            df['subject'].values[0],\n",
    "            df['block'].values[0],\n",
    "            df['probCP'].values[0]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_from_dots_ts(dot_ts, trials_ts, trials_df):\n",
    "    trial_dump_time = np.min(trials_ts[trials_ts>dot_ts])\n",
    "    return trials_df[trials_df['trialEnd'] == trial_dump_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coh 65.0, VD 0.4, CP 0, dir 0, S1, Quest, probCP nan\n",
      "coh 0.0, VD 0.2, CP 0, dir 180, S2, Block2, probCP 0.0\n",
      "coh 22.0, VD 0.4, CP 0, dir 180, S2, Block2, probCP 0.0\n",
      "coh 22.0, VD 0.4, CP 0, dir 0, S2, Block2, probCP 0.0\n",
      "coh 22.0, VD 0.3, CP 0, dir 180, S2, Block2, probCP 0.0\n",
      "coh 22.0, VD 0.3, CP 0, dir 180, S2, Block2, probCP 0.0\n",
      "coh 0.0, VD 0.2, CP 0, dir 180, S2, Block2, probCP 0.0\n",
      "coh 0.0, VD 0.3, CP 0, dir 0, S2, Block2, probCP 0.0\n",
      "coh 0.0, VD 0.3, CP 0, dir 180, S2, Block2, probCP 0.0\n",
      "coh 22.0, VD 0.1, CP 0, dir 0, S2, Block2, probCP 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    get_trial_params(\n",
    "        get_trial_from_dots_ts(ts[-i], trials, t)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good, for a given `seqDumpTime` value, I am able to recover the trial's parameters. All that remains to do is to add columns to the dots dataframe (and remove the `isActive` one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (MotionEnergy)",
   "language": "python",
   "name": "motionenergy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
