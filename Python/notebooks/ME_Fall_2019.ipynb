{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#NB-description\" data-toc-modified-id=\"NB-description-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>NB description</a></span></li><li><span><a href=\"#The-dotsPositions.csv-data\" data-toc-modified-id=\"The-dotsPositions.csv-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>The dotsPositions.csv data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Mapping-dots-to-trials\" data-toc-modified-id=\"Mapping-dots-to-trials-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Mapping dots to trials</a></span></li></ul></li><li><span><a href=\"#Write-a-dotsDB-HDF5-file\" data-toc-modified-id=\"Write-a-dotsDB-HDF5-file-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Write a dotsDB HDF5 file</a></span><ul class=\"toc-item\"><li><span><a href=\"#Write-HDF5-file\" data-toc-modified-id=\"Write-HDF5-file-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Write HDF5 file</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB description\n",
    "date: 03 Dec 2019  \n",
    "This notebook contains code that:\n",
    "- builds an HDF5 dotsDB database off of dotsPositions.csv files from the Fall 2019 data (subjects 10-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import seaborn as sns\n",
    "import h5py     \n",
    "import os.path\n",
    "\n",
    "# add location of custom modules to path\n",
    "sys.path.insert(0,'../modules/')\n",
    "sys.path.insert(0,'../modules/dots_db/dotsDB/')\n",
    "\n",
    "# custom modules\n",
    "import dotsDB as ddb\n",
    "import motionenergy as kiani_me\n",
    "import stimulus as stim\n",
    "import ME_functions as my_me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dotsPositions.csv data\n",
    "With the current pipeline, on the day of the session, a `.csv` file is written to disk with the FIRA data. Then, in the `motion_energy_Adrian` repo, I have MATLAB functions `reproduce_dots` and `batch_reproduce_dots` that write `_dotsPositions.csv` files to disk (one file per session).\n",
    "\n",
    "The first step here is to loop through the completed sessions, perform a `join` of the dots and fira data, and update a global `.csv` file, as well as session-specific `.csv` files, called `labeled_dots_<timestamp>.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_06_12_43/2019_11_06_12_43_dotsPositions.csv\r\n",
      "/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_26_13_11/2019_11_26_13_11_dotsPositions.csv\r\n",
      "/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_05_16_19/2019_11_05_16_19_dotsPositions.csv\r\n",
      "/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_20_15_34/2019_11_20_15_34_dotsPositions.csv\r\n",
      "/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_05_10_27/2019_11_05_10_27_dotsPositions.csv\r\n",
      "/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_19_13_15/2019_11_19_13_15_dotsPositions.csv\r\n",
      "/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_05_13_18/2019_11_05_13_18_dotsPositions.csv\r\n",
      "/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_25_16_12/2019_11_25_16_12_dotsPositions.csv\r\n"
     ]
    }
   ],
   "source": [
    "!find /home/adrian/SingleCP_DotsReversal/Fall2019/raw -name \"*dotsPositions.csv\" -print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_06_12_43/completed4AFCtrials_task100_date_2019_11_06_12_43.csv\r\n",
      "/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_26_13_11/completed4AFCtrials_task100_date_2019_11_26_13_11.csv\r\n",
      "/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_05_16_19/completed4AFCtrials_task100_date_2019_11_05_16_19.csv\r\n",
      "/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_20_15_34/completed4AFCtrials_task100_date_2019_11_20_15_34.csv\r\n",
      "/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_05_10_27/completed4AFCtrials_task100_date_2019_11_05_10_27.csv\r\n",
      "/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_19_13_15/completed4AFCtrials_task100_date_2019_11_19_13_15.csv\r\n",
      "/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_05_13_18/completed4AFCtrials_task100_date_2019_11_05_13_18.csv\r\n",
      "/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_25_16_12/completed4AFCtrials_task100_date_2019_11_25_16_12.csv\r\n"
     ]
    }
   ],
   "source": [
    "!find /home/adrian/SingleCP_DotsReversal/Fall2019/raw -name \"completed*100*.csv\" -print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_dots(timestamps, global_labeled_dots_filename, data_folder):\n",
    "    \"\"\"\n",
    "    fetches dots data outputted by MATLAB (the _dotsPositions.csv files) for specified session timestamps, adds\n",
    "    relevant fira data (join operation) and appends resulting 'labeled_dots' dataframe to the \n",
    "    global_labeled_dots_filename.\n",
    "    :param timestamps: list or tuple of strings of the form '2019_11_05_16_19'\n",
    "    :param global_labeled_dots_filename: string with full path and filename for global .csv file to write to\n",
    "    :param data_folder: string with path to folder '.../raw/' where fira and dotsPositions .csv data reside.\n",
    "    :return: None, but writes to file\n",
    "    \"\"\"\n",
    "    list_of_labeled_dots_dataframes = []\n",
    "    for ts in timestamps:\n",
    "        folder = data_folder + ts + '/'\n",
    "        fira = pd.read_csv(folder + 'completed4AFCtrials_task100_date_' + ts + '.csv')\n",
    "        dots = pd.read_csv(folder + ts + '_dotsPositions.csv')\n",
    "        dots = dots[dots['isActive'] == 1]\n",
    "        del dots['isActive'], dots['taskID'], dots['isCoherent']\n",
    "        try:\n",
    "            assert fira.index.min() == 0 and fira.index.max() == 819 and len(fira.index) == 820\n",
    "            assert dots['trialIx'].min() == 0 and dots['trialIx'].max() == 819\n",
    "        except AssertionError:\n",
    "            print(f'assert failed with timestamp {ts}')\n",
    "            continue\n",
    "        labeled_dots = dots.join(fira, on=\"trialIx\")\n",
    "        labeled_dots['trueVD'] = labeled_dots['dotsOff'] - labeled_dots['dotsOn']\n",
    "        labeled_dots['presenceCP'] = labeled_dots['reversal'] > 0\n",
    "        to_drop = ['trialIndex', 'RT', 'cpRT', 'dirCorrect', 'cpCorrect', \n",
    "            'randSeedBase', 'fixationOn', 'fixationStart', 'targetOn',\n",
    "            'choiceTime', 'cpChoiceTime', 'blankScreen', 'feedbackOn', \n",
    "            'cpScreenOn', 'dummyBlank', 'finalDuration', 'dotsOn', 'dotsOff']\n",
    "        labeled_dots.drop(columns=to_drop, inplace=True)\n",
    "        to_rename = {\n",
    "            'duration': 'viewingDuration',\n",
    "            'direction': 'initDirection',\n",
    "        }\n",
    "        labeled_dots.rename(columns=to_rename, inplace=True)\n",
    "        labeled_dots.dropna(subset=['dirChoice'], inplace=True)\n",
    "        list_of_labeled_dots_dataframes.append(labeled_dots)\n",
    "        \n",
    "    full_labeled_dots = pd.concat(list_of_labeled_dots_dataframes)\n",
    "    if os.path.exists(global_labeled_dots_filename):\n",
    "        full_labeled_dots.to_csv(global_labeled_dots_filename, index=False, mode='a+', header=False)\n",
    "    else:\n",
    "        full_labeled_dots.to_csv(global_labeled_dots_filename, index=False, mode='a+', header=True)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMPS = (\n",
    "    '2019_11_06_12_43',\n",
    "#     '2019_11_05_16_19',\n",
    "#     '2019_11_20_15_34',\n",
    "#     '2019_11_05_10_27',\n",
    "#     '2019_11_19_13_15',\n",
    "#     '2019_11_05_13_18',\n",
    "#     '2019_11_26_13_11',\n",
    "#     '2019_11_25_16_12',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/home/adrian/SingleCP_DotsReversal/Fall2019/raw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fira dataframe has index ranging from 0 to 819. The next step is to create a \"foreign key\" to this index into the dots dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOTS_LABELED = '/home/adrian/SingleCP_DotsReversal/processed/dots_fall_2019_v1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dots(TIMESTAMPS, DOTS_LABELED, DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOTS_DATA = '/home/adrian/SingleCP_DotsReversal/processed/dots_pilot_summer_2019.csv'\n",
    "\n",
    "# a=pd.read_csv(DOTS_DATA)\n",
    "# b=pd.read_csv(DOTS_LABELED)\n",
    "# b.shape[0] / 5\n",
    "# c=pd.read_csv('/home/adrian/SingleCP_DotsReversal/Fall2019/raw/2019_11_06_12_43/2019_11_06_12_43_dotsPositions.csv')\n",
    "# c.head()\n",
    "# a.head()\n",
    "# b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_csv(df):\n",
    "    \"\"\"df is a pandas.DataFrame\"\"\"\n",
    "    print(df.head())\n",
    "    print(len(df))\n",
    "    print(np.unique(df['taskID']))\n",
    "    try:\n",
    "        print(np.unique(df['pilotID']))\n",
    "    except KeyError:\n",
    "        print(np.unique(df['subject']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pd.read_csv('/home/adrian/SingleCP_DotsReversal/raw/2019_06_25_13_24/2019_06_25_13_24_dotsPositions.csv')\n",
    "# inspect_csv(a)\n",
    "\n",
    "# b = pd.read_csv('/home/adrian/SingleCP_DotsReversal/raw/2019_07_03_15_03/2019_07_03_15_03_dotsPositions.csv')\n",
    "# inspect_csv(b)\n",
    "\n",
    "# c = pd.read_csv('/home/adrian/SingleCP_DotsReversal/raw/2019_07_10_17_19/2019_07_10_17_19_dotsPositions.csv')\n",
    "# inspect_csv(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = [\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_06_25_13_24/2019_06_25_13_24_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_07_03_15_03/2019_07_03_15_03_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_06_24_13_31/2019_06_24_13_31_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_06_24_13_06/2019_06_24_13_06_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_07_17_17_17/2019_07_17_17_17_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_07_10_12_18/2019_07_10_12_18_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_06_20_13_27/2019_06_20_13_27_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_06_24_12_38/2019_06_24_12_38_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_07_10_17_19/2019_07_10_17_19_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_06_20_12_54/2019_06_20_12_54_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_06_21_13_08/2019_06_21_13_08_dotsPositions.csv',\n",
    "#     '/home/adrian/SingleCP_DotsReversal/raw/2019_07_12_11_11/2019_07_12_11_11_dotsPositions.csv'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas = [pd.read_csv(f) for f in files]\n",
    "# total = pd.concat(pandas)\n",
    "# inspect_csv(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final = total.loc[total['isActive'] == 1,:]\n",
    "# inspect_csv(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_to_file = False\n",
    "# if write_to_file:\n",
    "#     final.to_csv('dots_pilot_summer_2019.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a dotsDB HDF5 file\n",
    "Now that all the dotsPositions.csv data is collected into a single global .csv file, I wish to dump it all into an hdf5 database.\n",
    "\n",
    "Several actions need to be implemented.\n",
    "1. For each trial in the dotsPositions.csv data, I need to know: _coherence_, _viewing duration_, _presenceCP_, _direction_, _subject_, _block_ (_probCP_). For this, I will assume that the `trialEnd` (from FIRA) and `seqDumpTime` (from dotsPositions) timestamps are in the same unit.\n",
    "2. I need to decide how to organize my dotsDB hierarchically. Example is `subj15/probCP0.1/coh0/ansleft/CPno/VD100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df = pd.read_csv('/home/adrian/SingleCP_DotsReversal/processed/all_valid_data.csv')\n",
    "# dots = pd.read_csv(DOTS_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials = np.unique(trials_df['trialEnd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_params(df):\n",
    "    \"\"\"coherence, viewing duration, presenceCP, direction, subject, block, probCP\"\"\"\n",
    "    coh = df['coherence'].values[0]\n",
    "    vd = df['viewingDuration'].values[0]\n",
    "    pcp = df['presenceCP'].values[0]\n",
    "    idir = df['initDirection'].values[0]\n",
    "    subj = df['subject'].values[0]\n",
    "    block = df['block'].values[0]\n",
    "    Pcp = df['probCP'].values[0]\n",
    "    return coh, vd, pcp, idir, subj, block, Pcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_from_dots_ts(dot_ts, trials_ts, trials_df):\n",
    "    trial_dump_time = np.min(trials_ts[trials_ts>dot_ts])\n",
    "    assert trial_dump_time - dot_ts < .5, 'trialEnd occurs more than 0.5 sec after seqDumpTime'\n",
    "    return trials_df[trials_df['trialEnd'] == trial_dump_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trial_params(row, t, trials):\n",
    "    \"\"\"\n",
    "    function that adds appropriate values to trial parameter columns in dots dataframe\n",
    "    :param row: row from dataframe\n",
    "    :param t: dataframe with FIRA data\n",
    "    :param trials: numpy array of trialEnd timestamps (scalars)\n",
    "    \"\"\"\n",
    "    time = row['seqDumpTime']\n",
    "    try:\n",
    "        trial = get_trial_from_dots_ts(time, trials, t)\n",
    "    except AssertionError:\n",
    "        print(f'0.5 sec margin failed at row {row.name}')\n",
    "        return row\n",
    "    c,v,p,i,s,b,P = get_trial_params(trial)\n",
    "    row['coherence'] = c\n",
    "    row['viewingDuration'] = v\n",
    "    row['presenceCP'] = p\n",
    "    row['initDirection'] = i\n",
    "    row['subject'] = s\n",
    "    row['block'] = b\n",
    "    row['probCP'] = P\n",
    "    return row\n",
    "\n",
    "def set_nans(df):\n",
    "    if 'isActive' in df:\n",
    "        del df['isActive']\n",
    "    df['coherence'] = np.nan\n",
    "    df['viewingDuration'] = np.nan\n",
    "    df['presenceCP'] = np.nan\n",
    "    df['initDirection'] = np.nan\n",
    "    df['subject'] = np.nan\n",
    "    df['block'] = np.nan\n",
    "    df['probCP'] = np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good, for a given `seqDumpTime` value, I am able to recover the trial's parameters. All that remains to do is to add columns to the dots dataframe (and remove the `isActive` one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect_csv(dots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Following cell is SLOW! Around 30 min**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    dots = set_nans(dots)\n",
    "    dots = dots.apply(add_trial_params, axis=1, args=(trials_df, trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    dots_light = dots.copy()\n",
    "    dots_light.dropna(inplace=True)\n",
    "    dots.to_csv('dots_summer_2019_upgraded.csv')\n",
    "    dots_light.to_csv('dots_summer_2019_upgraded_light.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I forgot to record true duration and subject's choice!\n",
    "Rebelote..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL THIS HAS BEEN DONE AND YIELDED 'dots_summer_2019_upgraded_light_v2.csv'\n",
    "# dots = pd.read_csv(DOTS_LABELED)\n",
    "# del dots['Unnamed: 0']\n",
    "# gb = dots.groupby('seqDumpTime')\n",
    "\n",
    "# # Let's build a dataframe with four columns: seqDumpTime, cpChoice, trueVD and trialEnd\n",
    "# extras = pd.DataFrame(index=gb.groups.keys(), columns=['cpChoice', 'trueVD', 'trialEnd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_extras(row, t, trials):\n",
    "#     \"\"\"\n",
    "#     function that adds appropriate values to trial parameter columns in dots dataframe\n",
    "#     :param row: row from dataframe\n",
    "#     :param t: dataframe with FIRA data\n",
    "#     :param trials: numpy array of trialEnd timestamps (scalars)\n",
    "#     \"\"\"\n",
    "#     time = row.name\n",
    "#     try:\n",
    "#         trial = get_trial_from_dots_ts(time, trials, t)\n",
    "#     except AssertionError:\n",
    "#         print(f'0.5 sec margin failed at row {row.name}')\n",
    "#         return row\n",
    "#     c, v, te = trial['cpChoice'].values[0], trial['dotsOff'].values[0] - trial['dotsOn'].values[0], trial['trialEnd'].values[0]\n",
    "#     row['cpChoice'] = c  # could still be NA if block didn't require CP report\n",
    "#     row['trueVD'] = v\n",
    "#     row['trialEnd'] = te\n",
    "#     return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extras = pd.DataFrame(index=gb.groups.keys(), columns=['dirChoice', 'trueVD', 'trialEnd'])\n",
    "# extras = extras.apply(add_extras, axis=1, args=(trials_df, trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # join on seqDumpTime\n",
    "# dots = dots.join(extras, on='seqDumpTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dots.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should have added `dirChoice` instead of `cpChoice`!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DONE\n",
    "# dots = pd.read_csv(DOTS_LABELED)\n",
    "# trials_df.set_index('trialEnd', inplace=True)\n",
    "# dots = dots.join(trials_df[['dirChoice']], on='trialEnd')\n",
    "# dots.to_csv('dots_summer_2019_upgraded_light_v3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it turns out some rows have a `nan` value in the `dirChoice` column!\n",
    "I will drop them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dots = pd.read_csv(DOTS_LABELED)\n",
    "# old_length = len(dots)\n",
    "# dots.dropna(subset=['dirChoice'],inplace=True)\n",
    "# assert len(dots) < old_length\n",
    "# dots.to_csv('dots_summer_2019_upgraded_light_v4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write HDF5 file\n",
    "Now, I need to write an HDF5 file with the structure:\n",
    "`subj15/probCP0.1/coh0/ansleft/CPno/VD100`.\n",
    "\n",
    "I need to:\n",
    "- loop through the trials contained in the dots DF\n",
    "- port the dots data to dotsDB format\n",
    "- write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = pd.read_csv(DOTS_LABELED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = dots.groupby('seqDumpTime')  # recall gb.get_group() and gb['frameIdx'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, I would like to know the max value of `frameIdx` in each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs to be re-written\n",
    "def get_frames(df):\n",
    "    \"\"\"\n",
    "    get the dots data as a list of numpy arrays, as dotsDB requires them\n",
    "    \"\"\"\n",
    "    # (could/should probably be re-written with groupby and apply...)\n",
    "    num_frames = np.max(df[\"frameIdx\"]).astype(int)\n",
    "    assert not np.isnan(num_frames), 'NaN num_frames'\n",
    "    list_of_frames = []\n",
    "    for fr in range(num_frames):\n",
    "        frame_data = df[df[\"frameIdx\"] == (fr+1)]\n",
    "        list_of_frames.append(np.array(frame_data[['ypos','xpos']]))  # here I swap xpos with ypos for dotsDB\n",
    "    return list_of_frames\n",
    "\n",
    "def get_group_name(df):\n",
    "    \"\"\"\n",
    "    get the trial's parameters, and therefore the HDF5 group where the data should be appended\n",
    "    \"\"\"       \n",
    "    # get HDF5 group name\n",
    "    \n",
    "    def choice(c):\n",
    "        if c == 1:\n",
    "            return '/ansright' \n",
    "        elif c == 0:\n",
    "            return '/ansleft'\n",
    "        else:\n",
    "            raise ValueError(f'unexpected choice value {c}')\n",
    "            \n",
    "    def chgepoint(c):\n",
    "        return '/CPyes' if c else '/CPno'\n",
    "    \n",
    "    def viewdur(v):\n",
    "        return '/VD' + str(int(1000*v))\n",
    "    \n",
    "    def direction(d):\n",
    "        return 'left' if d else 'right'\n",
    "    \n",
    "    ss, pp, cc, ch, cp, vd, di= df[['subject', 'probCP', 'coherence', 'dirChoice', 'presenceCP', \n",
    "                               'viewingDuration', 'initDirection']].values[0,:]\n",
    "    \n",
    "    group_name = '/subj' + ss + \\\n",
    "                 '/probCP' + str(pp) + \\\n",
    "                 '/coh' + str(cc) + \\\n",
    "                 choice(ch) + chgepoint(cp) + viewdur(vd) + '/' + direction(di)\n",
    "                 \n",
    "    vals = {'coh': cc, \n",
    "            'subject': ss, \n",
    "            'probCP': pp, \n",
    "            'dirChoice': ch,\n",
    "            'presenceCP': cp,\n",
    "            'viewingDuration': vd, \n",
    "            'initDirection': direction(di)}\n",
    "    \n",
    "    return group_name, vals\n",
    "\n",
    "def write_dots_to_file(df, hdf5_file):\n",
    "    \"\"\"\n",
    "    The aim of this function is to write the dots info contained in the pandas.DataFrame df to a dotsDB HDF5 file.\n",
    "    df should only contain data about a single trial. \n",
    "    \n",
    "    head on df looks like this\n",
    "    xpos\typos\tisCoherent\tframeIdx\tseqDumpTime\tpilotID\ttaskID\tcoherence\tviewingDuration\tpresenceCP\tinitDirection\tsubject\tblock\tprobCP\tcpChoice\ttrueVD\ttrialEnd\tdirChoice\n",
    "\t0.722093\t0.416122\t1.0\t1.0\t1069.27719\t2.0\t3.0\t48.5\t0.3\t0.0\t180.0\tS1\tBlock2\t0.0\tNaN\t0.318517\t1069.535562\t0.0\n",
    "\t0.681785\t0.356234\t1.0\t1.0\t1069.27719\t2.0\t3.0\t48.5\t0.3\t0.0\t180.0\tS1\tBlock2\t0.0\tNaN\t0.318517\t1069.535562\t0.0\n",
    "\t0.445828\t0.914470\t1.0\t1.0\t1069.27719\t2.0\t3.0\t48.5\t0.3\t0.0\t180.0\tS1\tBlock2\t0.0\tNaN\t0.318517\t1069.535562\t0.0\n",
    "\t0.833181\t0.112126\t1.0\t1.0\t1069.27719\t2.0\t3.0\t48.5\t0.3\t0.0\t180.0\tS1\tBlock2\t0.0\tNaN\t0.318517\t1069.535562\t0.0\n",
    "\t0.013516\t0.354543\t1.0\t1.0\t1069.27719\t2.0\t3.0\t48.5\t0.3\t0.0\t180.0\tS1\tBlock2\t0.0\tNaN\t0.318517\t1069.535562\t0.0\n",
    "    \"\"\"\n",
    "    frames = get_frames(df)\n",
    "    gn, params = get_group_name(df)\n",
    "    \n",
    "    # exit function if number of frames too different from theoretical one \n",
    "    vd = params['viewingDuration']\n",
    "    num_frames = len(frames)\n",
    "    if abs(num_frames-vd*60) > 5:\n",
    "        tr = df['seqDumpTime'].values[0]\n",
    "        print(f'trial {tr} not written; discrepancy num_frames {num_frames} and VD {vd}')\n",
    "        return None\n",
    "    \n",
    "    cptime = 0.2 if params['presenceCP'] else None\n",
    "    parameters = dict(speed=5, \n",
    "                      density=90, \n",
    "                      coh_mean=params['coh'], \n",
    "                      coh_stdev=10, \n",
    "                      direction=params['initDirection'],\n",
    "                      num_frames=np.max(df[\"frameIdx\"]).astype(int),\n",
    "                      diameter=5, \n",
    "                      pixels_per_degree=(55.4612 / 2), \n",
    "                      dot_size_in_pxs=3, \n",
    "                      cp_time=cptime)\n",
    "    \n",
    "    stimulus = ddb.DotsStimulus(**parameters)\n",
    "    \n",
    "    ddb.write_stimulus_to_file(stimulus, 1, hdf5_file, \n",
    "                               pre_generated_stimulus=[frames],\n",
    "                               group_name=gn, append_to_group=True, max_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the first two seqDumpTime values for toy example\n",
    "# counter = 0\n",
    "# for ix in gb.groups.keys():\n",
    "#     counter += 1\n",
    "#     if counter == 6:\n",
    "#         break\n",
    "#     write_dots_to_file(dots[dots['seqDumpTime']==ix], 'test_pilot.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following cell takes a bit under 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall func is called twice the first time!\n",
    "\n",
    "# _ = gb.apply(write_dots_to_file, 'pilot_v3.h5')\n",
    "\n",
    "# no need to go in manually and delete the first entry in the dataset corresponding to \n",
    "# the first group element gb.groups.keys()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (MotionEnergy)",
   "language": "python",
   "name": "motionenergy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
