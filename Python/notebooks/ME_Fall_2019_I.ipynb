{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#NB-description\" data-toc-modified-id=\"NB-description-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>NB description</a></span></li><li><span><a href=\"#The-dotsPositions.csv-data\" data-toc-modified-id=\"The-dotsPositions.csv-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>The dotsPositions.csv data</a></span></li><li><span><a href=\"#Write-a-dotsDB-HDF5-file\" data-toc-modified-id=\"Write-a-dotsDB-HDF5-file-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Write a dotsDB HDF5 file</a></span><ul class=\"toc-item\"><li><span><a href=\"#Write-HDF5-file\" data-toc-modified-id=\"Write-HDF5-file-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Write HDF5 file</a></span></li></ul></li><li><span><a href=\"#Diagnostic\" data-toc-modified-id=\"Diagnostic-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Diagnostic</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB description\n",
    "date: 12 Dec 2019  \n",
    "This notebook contains code that:\n",
    "- builds an HDF5 dotsDB database off of dotsPositions.csv files from the Fall 2019 data (subjects 10-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import seaborn as sns\n",
    "import h5py     \n",
    "import os.path\n",
    "\n",
    "# add location of custom modules to path\n",
    "sys.path.insert(0,'../modules/')\n",
    "sys.path.insert(0,'../modules/dots_db/dotsDB/')\n",
    "\n",
    "# custom modules\n",
    "import dotsDB as ddb\n",
    "import motionenergy as kiani_me\n",
    "import stimulus as stim\n",
    "import ME_functions as my_me\n",
    "from basic_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dotsPositions.csv data\n",
    "With the current pipeline, on the day of the session, a `.csv` file is written to disk with the FIRA data. Then, in the `motion_energy_Adrian` repo, I have MATLAB functions `reproduce_dots` and `batch_reproduce_dots` that write `_dotsPositions.csv` files to disk (one file per session).\n",
    "\n",
    "The first step here is to loop through the completed sessions, perform a `join` of the dots and fira data, and update a global `.csv` file, as well as session-specific `.csv` files, called `labeled_dots_<timestamp>.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find /home/adrian/SingleCP_DotsReversal/Fall2019/raw -name \"*dotsPositions.csv\" -print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find /home/adrian/SingleCP_DotsReversal/Fall2019/raw -name \"completed*100*.csv\" -print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "list of written data timestamps:\n",
    "'2019_11_06_12_43'\n",
    "'2019_11_05_16_19',\n",
    "'2019_11_20_15_34',\n",
    "'2019_11_19_13_15',\n",
    "'2019_11_05_13_18',\n",
    "'2019_11_26_13_11',\n",
    "'2019_11_25_16_12',\n",
    "\n",
    "list of problematic timestamps that were NOT written\n",
    "'2019_11_05_10_27'  (subject=10 probCP=0.3)\n",
    "'''\n",
    "TIMESTAMPS = ('2019_12_11_12_21',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/home/adrian/SingleCP_DotsReversal/Fall2019/raw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fira dataframe has index ranging from 0 to 819. The next step is to create a \"foreign key\" to this index into the dots dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOTS_LABELED = '/home/adrian/SingleCP_DotsReversal/Fall2019/processed/dots_fall_2019_v2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this step with write to the DOTS_LABELED file, which contains labeled dots info necessary to dump to HDF5\n",
    "if True:\n",
    "    label_dots(TIMESTAMPS, DOTS_LABELED, DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a dotsDB HDF5 file\n",
    "Now that all the dotsPositions.csv data is collected into a single global .csv file, I wish to dump it all into an hdf5 database.\n",
    "\n",
    "Several actions need to be implemented.\n",
    "1. For each trial in the dotsPositions.csv data, I need to know: _coherence_, _viewing duration_, _presenceCP_, _direction_, _subject_, _block_ (_probCP_). For this, I will assume that the `trialEnd` (from FIRA) and `seqDumpTime` (from dotsPositions) timestamps are in the same unit.\n",
    "2. I need to decide how to organize my dotsDB hierarchically. Example is `subj15/probCP0.1/coh0/ansleft/CPno/VD100`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good, for a given `seqDumpTime` value, I am able to recover the trial's parameters. All that remains to do is to add columns to the dots dataframe (and remove the `isActive` one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Following cell is SLOW! Around 30 min**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I forgot to record true duration and subject's choice!\n",
    "Rebelote..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should have added `dirChoice` instead of `cpChoice`!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it turns out some rows have a `nan` value in the `dirChoice` column!\n",
    "I will drop them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write HDF5 file\n",
    "Now, I need to write an HDF5 file with the structure:\n",
    "`subj15/probCP0.1/coh0/ansleft/CPno/VD100`.\n",
    "\n",
    "I need to:\n",
    "- loop through the trials contained in the dots DF\n",
    "- port the dots data to dotsDB format\n",
    "- write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = pd.read_csv(DOTS_LABELED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005777, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dots.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important to only select the dates that we want to write to the HDF5 file\n",
    "dots = dots[dots['date'] == 201912111221]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = dots.groupby('trialEnd')  # recall gb.get_group() and gb['frameIdx'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, I would like to know the max value of `frameIdx` in each trial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following cell takes a bit under 9 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall func is called twice the first time!\n",
    "h5_filename = '/home/adrian/SingleCP_DotsReversal/Fall2019/processed/fall2019_v2.h5'\n",
    "if True:  # just a failsafe not to run this cell by mistake\n",
    "    _ = gb.apply(write_dots_to_file, h5_filename)\n",
    "\n",
    "# ??? need to go in manually and delete the first entry in the dataset corresponding to \n",
    "# the first group element gb.groups.keys()[0] ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xpos                  0.0731918\n",
       "ypos                   0.124284\n",
       "frameIdx                      1\n",
       "trialIx                     342\n",
       "taskID                      100\n",
       "trialStart          2.42235e+06\n",
       "trialEnd            2.42235e+06\n",
       "dirChoice                     1\n",
       "cpChoice                      1\n",
       "initDirection               180\n",
       "coherence                     0\n",
       "finalCPTime                 NaN\n",
       "subject                      14\n",
       "date               201912111221\n",
       "probCP                      0.3\n",
       "reversal                      0\n",
       "viewingDuration             0.4\n",
       "trueVD                  0.41693\n",
       "presenceCP                False\n",
       "Name: 411579, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trial that got written twice to dotsDB this time\n",
    "dots[dots['trialEnd']==list(gb.groups.keys())[0]].iloc[0,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual deletion of data resulting from double call to `write_dots_to_file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pb_dset_name = '/subj12/probCP0.3/coh27/ansright/CPno/VD300/right/px'\n",
    "\n",
    "f = h5py.File(h5_filename, 'r+')  # read/write\n",
    "# d = f[pb_dset_name]\n",
    "# try:\n",
    "#     d = d[1:]  # override first trial\n",
    "# except:\n",
    "#     raise\n",
    "# else:\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen, dupes = count_duplicates(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(seen.values()))\n",
    "print([sum(i) for i in dupes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tend = list(gb.groups.keys())[0]\n",
    "fira = pd.read_csv(DATA_FOLDER + 'full_2019_12_02.csv')\n",
    "fira.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fira[fira['date'] == 201911261311]['probCP'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fira['direction'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fira['dirChoice'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fira[fira['trialEnd'] == tend][['subject', 'dirChoice', 'duration', 'probCP', 'direction', 'coherence', 'reversal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fira.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fira[\n",
    "    (fira['subject'] == 10) & \n",
    "    (fira['probCP'] == 0.7) & \n",
    "    (fira['coherence'] == 61) & \n",
    "    (fira['dirChoice'] == 1) & \n",
    "    (fira['reversal'] == 0.2) & \n",
    "    (fira['duration'] == .4) & \n",
    "    (fira['direction'] == 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pb_dset_name[1:])\n",
    "print(count_trials_fira(pb_dset_name[1:], fira))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that only 4 trials correspond to the dataset for which the HDF5 length was doubled during the dump procedure is worrying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particular_dset = dots[\n",
    "    (dots['subject'] == 10) & (dots['probCP'] == 0.7) & (dots['coherence'] == 61) \\\n",
    "    & (dots['dirChoice'] == 0) & (dots['reversal'] == 0.2) & (dots['viewingDuration'] == .4) & \\\n",
    "    (dots['initDirection'] == 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particular_dset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particular_dset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particular_dset['trialIx'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not(any([len(dd) for dd in d[-47:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_fifty_three = [len(dd) for dd in d[:53]]\n",
    "all(first_fifty_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('min ', min(first_fifty_three), ' max ', max(first_fifty_three))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=f[pb_dset_name[:-3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a.attrs['frame_width_in_pxs'] ** 2) * round(.4 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a.attrs['frame_width_in_pxs'] ** 2) * round(.437 * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last 47 items in the problematic dataset are empty and the first 53 are not. Each trial has a number of frames corresponding to some duration between 400 and 437 msec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that 2 out of the three unique trials in the dataset (one of them is trivially 0) were duplicated between 16 and 34 times!\n",
    "\n",
    "Did this happen with other datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes 1 or 2 min to run with subjects 10-13\n",
    "dsets = {}\n",
    "f.visititems(count_meta, dsets)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes_exist = 0\n",
    "num_dupes = []\n",
    "min_repeat, max_repeat = [], []\n",
    "for stats in dsets.values():\n",
    "    if stats[1]:\n",
    "        dupes_exist += 1\n",
    "        min_repeat.append(min([v for v in stats[0].values() if v > 1]))\n",
    "        max_repeat.append(max([v for v in stats[0].values() if v > 1]))\n",
    "        num_dupes.append(len(stats[1]))\n",
    "print(f'dupes exist in {dupes_exist} out of {len(dsets)} datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(num_dupes), max(num_dupes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(num_dupes);\n",
    "plt.title('number of duplicates within a dataset');\n",
    "plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears duplicates exist in several hundreds datasets. This is worrying :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(np.array([True, True, False])) == tuple(np.array([True, True, False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(min_repeat);\n",
    "plt.title('Min number of repeats for single trial within a dataset');\n",
    "plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(max_repeat);\n",
    "plt.title('Max number of repeats for single trial within a dataset');\n",
    "plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And when repeats occur, they occur quite a lot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step would be to carefully count the number of trials per condition in FIRA, in DOTS and in dotsDB, and analyze the match/mismatch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting trials in three databases (fira + dots + dotsDB) in the cell below takes 20 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By this cell, make sure 'dots', 'fira' and 'dsets' are defined.\n",
    "# dots and fira are pandas.DataFrame objects, dsets is the dict of counts\n",
    "# The goal here is to build a dataframe with three columns: dots, fira, h5.\n",
    "# Each row in this dataframe is a particular dataset in the hdf5 database\n",
    "# each entry is the trial count for this particular dataset\n",
    "\n",
    "\n",
    "index_as_list, dicts = [], []\n",
    "counter = 0\n",
    "for name in dsets:\n",
    "    counter += 1\n",
    "    if (counter % 10) == 0:\n",
    "        print(counter)\n",
    "    index_as_list.append(name)\n",
    "    curr_dict = {}\n",
    "    h5_count = count_h5(dsets[name][0])\n",
    "    curr_dict['h5'] = h5_count\n",
    "    if (counter % 10) == 0:\n",
    "        print(f'counted h5 {h5_count}')\n",
    "        \n",
    "    fira_count = count_trials_fira(name, fira)\n",
    "    curr_dict['fira'] = fira_count\n",
    "    if (counter % 10) == 0:\n",
    "        print(f'counted fira {fira_count}')\n",
    "        \n",
    "    dots_count = count_trials_dots(name, dots)\n",
    "    curr_dict['dots'] = dots_count\n",
    "    if (counter % 10) == 0:\n",
    "        print(f'counted dots {dots_count}')\n",
    "        print()\n",
    "        \n",
    "    dicts.append(curr_dict)\n",
    "counts = pd.DataFrame(dicts, index=index_as_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(index_as_list)), counts['h5'], label='h5')\n",
    "plt.plot(range(len(index_as_list)), counts['fira'], label='fira')\n",
    "plt.plot(range(len(index_as_list)), counts['dots'], label='dots')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_vs_fira = counts[counts['h5'] != counts['fira']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(counts['fira'] != counts['dots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_vs_fira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.loc[pb_dset_name[1:]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (MotionEnergy)",
   "language": "python",
   "name": "motionenergy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
